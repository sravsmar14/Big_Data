{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "37e4dd8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lastException: Throwable = null\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    }
   ],
   "source": [
    "import org.apache.spark.sql.SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "087594a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spark = org.apache.spark.sql.SparkSession@4b325e55\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "org.apache.spark.sql.SparkSession@4b325e55"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val spark = SparkSession.\n",
    "    builder.\n",
    "    config(\"spark.ui.port\", \"0\").\n",
    "    config(\"spark.sql.warehouse.dir\", \"/user/itv001389/warehouse\").\n",
    "    enableHiveSupport.\n",
    "    master(\"yarn\").\n",
    "    appName(\"Getting Started - Spark with Scala\").\n",
    "    getOrCreate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebee953b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"use raj\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57535513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|   68883|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select count(*) from orders\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "db91e12c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------+-----------+\n",
      "|database|tableName         |isTemporary|\n",
      "+--------+------------------+-----------+\n",
      "|raj     |order_immu        |false      |\n",
      "|raj     |orderitem_nor     |false      |\n",
      "|raj     |orderitem_orc     |false      |\n",
      "|raj     |orderitem_par     |false      |\n",
      "|raj     |order_items       |false      |\n",
      "|raj     |order_items_part  |false      |\n",
      "|raj     |order_oi          |false      |\n",
      "|raj     |order_oi_cast     |false      |\n",
      "|raj     |order_oi_cast1    |false      |\n",
      "|raj     |order_oi_part     |false      |\n",
      "|raj     |order_oi_part1    |false      |\n",
      "|raj     |order_oi_part2    |false      |\n",
      "|raj     |order_oi_partit   |false      |\n",
      "|raj     |order_oi_partition|false      |\n",
      "|raj     |order_oi_sum1     |false      |\n",
      "|raj     |order_oi_sum2     |false      |\n",
      "|raj     |order_orc         |false      |\n",
      "|raj     |orders            |false      |\n",
      "|raj     |orders_buck       |false      |\n",
      "|raj     |orders_buck1      |false      |\n",
      "+--------+------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show tables\").show(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c4cfaef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Waiting for a Spark session to start..."
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "df = [order_id: int, Order_date: timestamp ... 2 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[order_id: int, Order_date: timestamp ... 2 more fields]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df=spark.read.parquet(\"hdfs://m01.itversity.com:9000/user/itv001389/warehouse/raj.db/orders\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a8ebaf64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- order_id: integer (nullable = true)\n",
      " |-- Order_date: timestamp (nullable = true)\n",
      " |-- Order_product_id: integer (nullable = true)\n",
      " |-- Order_status: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9791f626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68883"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b0f03f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+----------------+---------------+\n",
      "|order_id|Order_date         |Order_product_id|Order_status   |\n",
      "+--------+-------------------+----------------+---------------+\n",
      "|1       |2013-07-25 00:00:00|11599           |CLOSED         |\n",
      "|2       |2013-07-25 00:00:00|256             |PENDING_PAYMENT|\n",
      "|3       |2013-07-25 00:00:00|12111           |COMPLETE       |\n",
      "|4       |2013-07-25 00:00:00|8827            |CLOSED         |\n",
      "|5       |2013-07-25 00:00:00|11318           |COMPLETE       |\n",
      "+--------+-------------------+----------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5,false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9d131823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df1 = [Order_id: int, Order_date: timestamp ... 2 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "lastException: Throwable = null\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[Order_id: int, Order_date: timestamp ... 2 more fields]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df1=spark.read.format(\"orc\").load(\"hdfs://m01.itversity.com:9000/user/itv001389/warehouse/raj.db/order_orc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dc1b29e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Order_id: integer (nullable = true)\n",
      " |-- Order_date: timestamp (nullable = true)\n",
      " |-- Order_product_id: integer (nullable = true)\n",
      " |-- order_status: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "961cf28e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68883"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4a2976fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+----------------+---------------+\n",
      "|Order_id|Order_date         |Order_product_id|order_status   |\n",
      "+--------+-------------------+----------------+---------------+\n",
      "|1       |2013-07-25 00:00:00|11599           |CLOSED         |\n",
      "|2       |2013-07-25 00:00:00|256             |PENDING_PAYMENT|\n",
      "|3       |2013-07-25 00:00:00|12111           |COMPLETE       |\n",
      "|4       |2013-07-25 00:00:00|8827            |CLOSED         |\n",
      "|5       |2013-07-25 00:00:00|11318           |COMPLETE       |\n",
      "+--------+-------------------+----------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show(5,false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55b37571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df_table = [order_id: int, Order_date: timestamp ... 2 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[order_id: int, Order_date: timestamp ... 2 more fields]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df_table=spark.read.table(\"raj.orders\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fb6938",
   "metadata": {},
   "source": [
    "####   saveAsTable will create a new table if the table doesn't exist and load the data.If table exists need to use overwrite\n",
    "####   Append is used If we want to maintain the historical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0d49724",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_table.write.format(\"orc\").mode(\"append\").saveAsTable(\"raj.orders_write1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f454e00b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+----------------+---------------+\n",
      "|order_id|Order_date         |Order_product_id|Order_status   |\n",
      "+--------+-------------------+----------------+---------------+\n",
      "|1       |2013-07-25 00:00:00|11599           |CLOSED         |\n",
      "|2       |2013-07-25 00:00:00|256             |PENDING_PAYMENT|\n",
      "|3       |2013-07-25 00:00:00|12111           |COMPLETE       |\n",
      "|4       |2013-07-25 00:00:00|8827            |CLOSED         |\n",
      "|5       |2013-07-25 00:00:00|11318           |COMPLETE       |\n",
      "+--------+-------------------+----------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from raj.orders_write1 limit 5\").show(false)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586f1ac3",
   "metadata": {},
   "source": [
    "##### insertInto is used when a table is already exists and need to change file format \n",
    "#####  overwrite is used if we dont want to maintain the historical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fad6a15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_table.write.format(\"orc\").mode(\"overwrite\").insertInto(\"raj.orders_write\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db01dd99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68883"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"select * from raj.orders_write\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f8e466d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+----------------+---------------+\n",
      "|order_id|Order_date         |Order_product_id|Order_status   |\n",
      "+--------+-------------------+----------------+---------------+\n",
      "|1       |2013-07-25 00:00:00|11599           |CLOSED         |\n",
      "|2       |2013-07-25 00:00:00|256             |PENDING_PAYMENT|\n",
      "|3       |2013-07-25 00:00:00|12111           |COMPLETE       |\n",
      "|4       |2013-07-25 00:00:00|8827            |CLOSED         |\n",
      "|5       |2013-07-25 00:00:00|11318           |COMPLETE       |\n",
      "+--------+-------------------+----------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.table(\"raj.orders_write\").show(5,false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0cdbc74a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+--------------------------------------------------------------------------+-------+\n",
      "|col_name                    |data_type                                                                 |comment|\n",
      "+----------------------------+--------------------------------------------------------------------------+-------+\n",
      "|order_id                    |int                                                                       |null   |\n",
      "|Order_date                  |timestamp                                                                 |null   |\n",
      "|Order_product_id            |int                                                                       |null   |\n",
      "|Order_status                |string                                                                    |null   |\n",
      "|                            |                                                                          |       |\n",
      "|# Detailed Table Information|                                                                          |       |\n",
      "|Database                    |raj                                                                       |       |\n",
      "|Table                       |orders_write                                                              |       |\n",
      "|Owner                       |itv001389                                                                 |       |\n",
      "|Created Time                |Mon Oct 18 12:11:48 EDT 2021                                              |       |\n",
      "|Last Access                 |Wed Dec 31 19:00:00 EST 1969                                              |       |\n",
      "|Created By                  |Spark 2.4.7                                                               |       |\n",
      "|Type                        |MANAGED                                                                   |       |\n",
      "|Provider                    |parquet                                                                   |       |\n",
      "|Table Properties            |[transient_lastDdlTime=1634573508]                                        |       |\n",
      "|Statistics                  |487493 bytes                                                              |       |\n",
      "|Location                    |hdfs://m01.itversity.com:9000/user/itv001389/warehouse/raj.db/orders_write|       |\n",
      "|Serde Library               |org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe               |       |\n",
      "|InputFormat                 |org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat             |       |\n",
      "|OutputFormat                |org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat            |       |\n",
      "+----------------------------+--------------------------------------------------------------------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"describe formatted raj.orders_write\").show(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0464896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01_Table_Creations.ipynb\t      07_Bucketing_practice.ipynb\n",
      "02_Order_table_creations.ipynb\t      08_Handling_small_files.ipynb\n",
      "03_OrderItem_table_creation.ipynb     09_Spark.ipynb\n",
      "04_Order_OrderItem_Joins.ipynb\t      filename.hql\n",
      "05_Order_OrderItems_Partitions.ipynb  ${system:java.io.tmpdir}\n",
      "06_Msck_Practise.ipynb\t\t      test.txt\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b6ddc92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\n",
      "-rw-r--r--   3 itv001389 supergroup          0 2021-10-18 12:11 hdfs://m01.itversity.com:9000/user/itv001389/warehouse/raj.db/orders_write/_SUCCESS\n",
      "-rw-r--r--   3 itv001389 supergroup     487493 2021-10-18 12:11 hdfs://m01.itversity.com:9000/user/itv001389/warehouse/raj.db/orders_write/part-00000-47d17d10-9b1c-4dc5-87de-6ee1efb948cf-c000.snappy.parquet\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -ls hdfs://m01.itversity.com:9000/user/itv001389/warehouse/raj.db/orders_write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1098fdca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df = [order_id: int, Order_date: timestamp ... 2 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[order_id: int, Order_date: timestamp ... 2 more fields]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df=spark.read.parquet(\"hdfs://m01.itversity.com:9000/user/itv001389/warehouse/raj.db/orders\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec2a739a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.format(\"orc\").mode(\"overwrite\").save(\"hdfs://m01.itversity.com:9000/user/itv001389/warehouse/raj.db/sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524de600",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"show tables\").show(30,false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fdca1534",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"Orders_temp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ac6116",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"select * from Orders_temp\").show(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0047b666",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df1 = [order_item_id: int, order_item_order_id: int ... 4 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "lastException: Throwable = null\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[order_item_id: int, order_item_order_id: int ... 4 more fields]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df1=spark.read.parquet(\"hdfs://m01.itversity.com:9000/user/itv001389/warehouse/raj.db/order_items_par\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ea0771bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.write.format(\"orc\").mode(\"overwrite\").save(\"hdfs://m01.itversity.com:9000/user/itv001389/warehouse/raj.db/order_items_orc_spark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ed5a266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"drop table Orders_temp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd6e682d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lastException: Throwable = null\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    spark.sql(\"create table raj.order_o (order_id int,order_date timestamp,order_product_id int,order_status string) row format delimited fields terminated by ',' stored as textfile location 'hdfs://m01.itversity.com:9000/user/itv001389/warehouse/raj.db/order.simple' \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8cf5c9b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+--------------------------------------------------------------------------+-------+\n",
      "|col_name                    |data_type                                                                 |comment|\n",
      "+----------------------------+--------------------------------------------------------------------------+-------+\n",
      "|order_id                    |int                                                                       |null   |\n",
      "|order_date                  |timestamp                                                                 |null   |\n",
      "|order_product_id            |int                                                                       |null   |\n",
      "|order_status                |string                                                                    |null   |\n",
      "|                            |                                                                          |       |\n",
      "|# Detailed Table Information|                                                                          |       |\n",
      "|Database                    |raj                                                                       |       |\n",
      "|Table                       |order_o                                                                   |       |\n",
      "|Owner                       |itv001389                                                                 |       |\n",
      "|Created Time                |Fri Oct 22 10:08:46 EDT 2021                                              |       |\n",
      "|Last Access                 |Wed Dec 31 19:00:00 EST 1969                                              |       |\n",
      "|Created By                  |Spark 2.4.7                                                               |       |\n",
      "|Type                        |EXTERNAL                                                                  |       |\n",
      "|Provider                    |hive                                                                      |       |\n",
      "|Table Properties            |[transient_lastDdlTime=1634911726]                                        |       |\n",
      "|Location                    |hdfs://m01.itversity.com:9000/user/itv001389/warehouse/raj.db/order.simple|       |\n",
      "|Serde Library               |org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe                        |       |\n",
      "|InputFormat                 |org.apache.hadoop.mapred.TextInputFormat                                  |       |\n",
      "|OutputFormat                |org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat                |       |\n",
      "|Storage Properties          |[field.delim=,, serialization.format=,]                                   |       |\n",
      "+----------------------------+--------------------------------------------------------------------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"describe formatted raj.order_o\").show(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6bfaff82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"insert into table raj.order_o select order_id,cast(order_date as date),order_product_id,order_status from raj.orders\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "31fae070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+--------------------------------------------------------------------------+-------+\n",
      "|col_name                    |data_type                                                                 |comment|\n",
      "+----------------------------+--------------------------------------------------------------------------+-------+\n",
      "|order_id                    |int                                                                       |null   |\n",
      "|order_date                  |timestamp                                                                 |null   |\n",
      "|order_product_id            |int                                                                       |null   |\n",
      "|order_status                |string                                                                    |null   |\n",
      "|                            |                                                                          |       |\n",
      "|# Detailed Table Information|                                                                          |       |\n",
      "|Database                    |raj                                                                       |       |\n",
      "|Table                       |order_o                                                                   |       |\n",
      "|Owner                       |itv001389                                                                 |       |\n",
      "|Created Time                |Fri Oct 22 10:08:46 EDT 2021                                              |       |\n",
      "|Last Access                 |Wed Dec 31 19:00:00 EST 1969                                              |       |\n",
      "|Created By                  |Spark 2.4.7                                                               |       |\n",
      "|Type                        |EXTERNAL                                                                  |       |\n",
      "|Provider                    |hive                                                                      |       |\n",
      "|Table Properties            |[transient_lastDdlTime=1634912188, STATS_GENERATED_VIA_STATS_TASK=true]   |       |\n",
      "|Statistics                  |2862178 bytes                                                             |       |\n",
      "|Location                    |hdfs://m01.itversity.com:9000/user/itv001389/warehouse/raj.db/order.simple|       |\n",
      "|Serde Library               |org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe                        |       |\n",
      "|InputFormat                 |org.apache.hadoop.mapred.TextInputFormat                                  |       |\n",
      "|OutputFormat                |org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat                |       |\n",
      "+----------------------------+--------------------------------------------------------------------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"describe formatted raj.order_o\").show(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3fe635a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lastException = null\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "ename": "org.apache.spark.sql.AnalysisException",
     "evalue": "Table or view not found: `raj`.`order_o`; line 1 pos 14;\n'GlobalLimit 5\n+- 'LocalLimit 5\n   +- 'Project [*]\n      +- 'UnresolvedRelation `raj`.`order_o`\n",
     "output_type": "error",
     "traceback": [
      "org.apache.spark.sql.AnalysisException: Table or view not found: `raj`.`order_o`; line 1 pos 14;",
      "'GlobalLimit 5",
      "+- 'LocalLimit 5",
      "   +- 'Project [*]",
      "      +- 'UnresolvedRelation `raj`.`order_o`",
      "  at org.apache.spark.sql.catalyst.analysis.package$AnalysisErrorAt.failAnalysis(package.scala:42)",
      "  at org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1.apply(CheckAnalysis.scala:91)",
      "  at org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1.apply(CheckAnalysis.scala:86)",
      "  at org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:126)",
      "  at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$foreachUp$1.apply(TreeNode.scala:125)",
      "  at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$foreachUp$1.apply(TreeNode.scala:125)",
      "  at scala.collection.immutable.List.foreach(List.scala:392)",
      "  at org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:125)",
      "  at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$foreachUp$1.apply(TreeNode.scala:125)",
      "  at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$foreachUp$1.apply(TreeNode.scala:125)",
      "  at scala.collection.immutable.List.foreach(List.scala:392)",
      "  at org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:125)",
      "  at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$foreachUp$1.apply(TreeNode.scala:125)",
      "  at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$foreachUp$1.apply(TreeNode.scala:125)",
      "  at scala.collection.immutable.List.foreach(List.scala:392)",
      "  at org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:125)",
      "  at org.apache.spark.sql.catalyst.analysis.CheckAnalysis$class.checkAnalysis(CheckAnalysis.scala:86)",
      "  at org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis(Analyzer.scala:95)",
      "  at org.apache.spark.sql.catalyst.analysis.Analyzer$$anonfun$executeAndCheck$1.apply(Analyzer.scala:108)",
      "  at org.apache.spark.sql.catalyst.analysis.Analyzer$$anonfun$executeAndCheck$1.apply(Analyzer.scala:105)",
      "  at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:201)",
      "  at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:105)",
      "  at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:58)",
      "  at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:56)",
      "  at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:48)",
      "  at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:78)",
      "  at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:643)",
      "  ... 42 elided"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from raj.order_o limit 5 \").show(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b59e6ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"drop table raj.order_o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6357ef6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df = [order_id: int, Order_date: timestamp ... 2 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "lastException: Throwable = null\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[order_id: int, Order_date: timestamp ... 2 more fields]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df=spark.read.parquet(\"hdfs://m01.itversity.com:9000/user/itv001389/warehouse/raj.db/orders\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2b96b6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lastException: Throwable = null\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    }
   ],
   "source": [
    "df.write.format(\"orc\").mode(\"overwrite\").save(\"hdfs://m01.itversity.com:9000/user/itv001389/warehouse/raj.db/orders_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c40e517",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf1dd27a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+----------------+---------------+\n",
      "|order_id|Order_date         |Order_product_id|Order_status   |\n",
      "+--------+-------------------+----------------+---------------+\n",
      "|1       |2013-07-25 00:00:00|11599           |CLOSED         |\n",
      "|2       |2013-07-25 00:00:00|256             |PENDING_PAYMENT|\n",
      "|3       |2013-07-25 00:00:00|12111           |COMPLETE       |\n",
      "|4       |2013-07-25 00:00:00|8827            |CLOSED         |\n",
      "|5       |2013-07-25 00:00:00|11318           |COMPLETE       |\n",
      "+--------+-------------------+----------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from test limit 5\").show(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ee8afca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[order_id: int, order_date: date ... 2 more fields]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"select order_id,cast(order_date as date),order_product_id,order_status from test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f81ccffd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df1 = [order_id: int, order_date: date ... 2 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[order_id: int, order_date: date ... 2 more fields]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df1=spark.sql(\"select order_id,cast(order_date as date),order_product_id,order_status from test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e797636c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+----------------+---------------+\n",
      "|order_id|order_date|order_product_id|order_status   |\n",
      "+--------+----------+----------------+---------------+\n",
      "|1       |2013-07-25|11599           |CLOSED         |\n",
      "|2       |2013-07-25|256             |PENDING_PAYMENT|\n",
      "|3       |2013-07-25|12111           |COMPLETE       |\n",
      "|4       |2013-07-25|8827            |CLOSED         |\n",
      "|5       |2013-07-25|11318           |COMPLETE       |\n",
      "+--------+----------+----------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show(5,false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1139f155",
   "metadata": {},
   "outputs": [
    {
     "ename": "java.util.NoSuchElementException",
     "evalue": "None.get",
     "output_type": "error",
     "traceback": [
      "java.util.NoSuchElementException: None.get",
      "  at scala.None$.get(Option.scala:347)",
      "  at scala.None$.get(Option.scala:345)",
      "  at org.apache.spark.sql.execution.datasources.BasicWriteJobStatsTracker$.metrics(BasicWriteStatsTracker.scala:173)",
      "  at org.apache.spark.sql.execution.command.DataWritingCommand$class.metrics(DataWritingCommand.scala:51)",
      "  at org.apache.spark.sql.execution.command.CreateDataSourceTableAsSelectCommand.metrics$lzycompute(createDataSourceTables.scala:138)",
      "  at org.apache.spark.sql.execution.command.CreateDataSourceTableAsSelectCommand.metrics(createDataSourceTables.scala:138)",
      "  at org.apache.spark.sql.execution.command.DataWritingCommandExec.metrics$lzycompute(commands.scala:100)",
      "  at org.apache.spark.sql.execution.command.DataWritingCommandExec.metrics(commands.scala:100)",
      "  at org.apache.spark.sql.execution.SparkPlanInfo$.fromSparkPlan(SparkPlanInfo.scala:56)",
      "  at org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:78)",
      "  at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:127)",
      "  at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:75)",
      "  at org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:696)",
      "  at org.apache.spark.sql.DataFrameWriter.createTable(DataFrameWriter.scala:494)",
      "  at org.apache.spark.sql.DataFrameWriter.saveAsTable(DataFrameWriter.scala:473)",
      "  at org.apache.spark.sql.DataFrameWriter.saveAsTable(DataFrameWriter.scala:429)",
      "  ... 42 elided"
     ]
    }
   ],
   "source": [
    "df1.write.mode(\"overwrite\").saveAsTable(\"raj.order_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6833a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark 2 - Scala",
   "language": "scala",
   "name": "spark_2_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
