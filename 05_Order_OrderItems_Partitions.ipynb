{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aad5a5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "374db5b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spark = org.apache.spark.sql.SparkSession@4fad5511\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "org.apache.spark.sql.SparkSession@4fad5511"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val spark = SparkSession.\n",
    "    builder.\n",
    "    config(\"spark.ui.port\", \"0\").\n",
    "    config(\"spark.sql.warehouse.dir\", \"/user/itv001389/warehouse\").\n",
    "    enableHiveSupport.\n",
    "    master(\"yarn\").\n",
    "    appName(\"Getting Started - Spark with Scala\").\n",
    "    getOrCreate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ebb4aa89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spark.implicits._\n",
    "import spark.sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e9d3d77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sqlContext.setConf(\"hive.exec.max.dynamic.partitions.pernode\" , \"100000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3fcd2fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sqlContext.setConf(\"hive.exec.max.dynamic.partitions\",\"100000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d87cdd38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"use Raj\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3aeaef23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------+-----------+\n",
      "|database|tableName         |isTemporary|\n",
      "+--------+------------------+-----------+\n",
      "|raj     |order_immu        |false      |\n",
      "|raj     |orderitem_nor     |false      |\n",
      "|raj     |orderitem_orc     |false      |\n",
      "|raj     |orderitem_par     |false      |\n",
      "|raj     |order_items       |false      |\n",
      "|raj     |order_items_part  |false      |\n",
      "|raj     |order_oi          |false      |\n",
      "|raj     |order_oi_cast     |false      |\n",
      "|raj     |order_oi_cast1    |false      |\n",
      "|raj     |order_oi_part     |false      |\n",
      "|raj     |order_oi_part1    |false      |\n",
      "|raj     |order_oi_part2    |false      |\n",
      "|raj     |order_oi_partit   |false      |\n",
      "|raj     |order_oi_partition|false      |\n",
      "|raj     |order_oi_sum1     |false      |\n",
      "|raj     |order_oi_sum2     |false      |\n",
      "|raj     |order_orc         |false      |\n",
      "|raj     |orders            |false      |\n",
      "|raj     |order_skip_header |false      |\n",
      "|raj     |order_skip_header1|false      |\n",
      "+--------+------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show tables\").show(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c2900f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+--------------------------------------------------------------------+-------+\n",
      "|col_name                    |data_type                                                           |comment|\n",
      "+----------------------------+--------------------------------------------------------------------+-------+\n",
      "|order_id                    |int                                                                 |null   |\n",
      "|Order_date                  |timestamp                                                           |null   |\n",
      "|Order_product_id            |int                                                                 |null   |\n",
      "|Order_status                |string                                                              |null   |\n",
      "|                            |                                                                    |       |\n",
      "|# Detailed Table Information|                                                                    |       |\n",
      "|Database                    |raj                                                                 |       |\n",
      "|Table                       |orders                                                              |       |\n",
      "|Owner                       |itv001389                                                           |       |\n",
      "|Created Time                |Sat Oct 16 03:39:18 EDT 2021                                        |       |\n",
      "|Last Access                 |Wed Dec 31 19:00:00 EST 1969                                        |       |\n",
      "|Created By                  |Spark 2.4.7                                                         |       |\n",
      "|Type                        |MANAGED                                                             |       |\n",
      "|Provider                    |parquet                                                             |       |\n",
      "|Table Properties            |[transient_lastDdlTime=1634369958]                                  |       |\n",
      "|Statistics                  |487493 bytes                                                        |       |\n",
      "|Location                    |hdfs://m01.itversity.com:9000/user/itv001389/warehouse/raj.db/orders|       |\n",
      "|Serde Library               |org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe         |       |\n",
      "|InputFormat                 |org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat       |       |\n",
      "|OutputFormat                |org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat      |       |\n",
      "+----------------------------+--------------------------------------------------------------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"describe formatted orders\").show(false)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38032f2b",
   "metadata": {},
   "source": [
    "##### The division of table into related parts based on some columns is Partitioning.\n",
    "#####  Partitions are created on columns on which we use filter conditions multiple times.\n",
    "#####  There are two types of Partitions 1.Static Partition 2.Dynamic partition\n",
    "#####  In static partition method we need to manually specify the partitions.This will bluntly load\n",
    "#####  whereas in dynamic method we can dynamically partition the table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833bd1ce",
   "metadata": {},
   "source": [
    "##### Horizontal division of table takes place in partition.\n",
    "#####  We generally create partitions are the columns whose cardinality value is less and also whose column is mostly used in WHERE clause in SQL\n",
    "#####  If we query partition table then query will directly hit that partition and retrive data instead of scanning entire table\n",
    "#####  There are two types of partitions 1) Static 2) Dynamic\n",
    "#####  Static partition ---> we need to manually define the partition value\n",
    "##### There are two methods in Static partition 1) Load method 2) Insert select method\n",
    "##### Load method will directly load the data without checking column order whereas in insert select we can have control which column should go where\n",
    "##### Dynamic partition ---> In this partitions are created dynamically based on the unique values in that column.This gives more flexibily as we no need to specify partition values manully\n",
    "##### Dynamic partition also have two methods  1) Load method 2) Insert select method\n",
    "##### Load method will directly load the data without checking column order whereas in insert select we can have control which column should go where\n",
    "##### In order to have dynamic partition enabled we need to use below mentioned two properties\n",
    "\n",
    "##### set hive.exec.dynamic.partition=true; \n",
    "##### set hive.exec.dynamic.partition.mode=nonstrict;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64b916fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lastException: Throwable = null\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"create table Raj.orders_part(order_id int,order_date timestamp,order_product_id int) partitioned by (order_status string) \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadca5b5",
   "metadata": {},
   "source": [
    "#####   Property should be added for dynamic partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2aa5d96d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lastException: Throwable = null\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[key: string, value: string]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"set hive.exec.dynamic.partition.mode=nonstrict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f74a449f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"insert into table Raj.orders_part select * from orders\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92c268e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+----------------+------------+\n",
      "|order_id|order_date         |order_product_id|order_status|\n",
      "+--------+-------------------+----------------+------------+\n",
      "|21      |2013-07-25 00:00:00|2711            |PENDING     |\n",
      "|36      |2013-07-25 00:00:00|5649            |PENDING     |\n",
      "|39      |2013-07-25 00:00:00|8214            |PENDING     |\n",
      "|42      |2013-07-25 00:00:00|9776            |PENDING     |\n",
      "|44      |2013-07-25 00:00:00|10500           |PENDING     |\n",
      "|49      |2013-07-25 00:00:00|1871            |PENDING     |\n",
      "|55      |2013-07-25 00:00:00|2052            |PENDING     |\n",
      "|68      |2013-07-25 00:00:00|4320            |PENDING     |\n",
      "|85      |2013-07-25 00:00:00|1485            |PENDING     |\n",
      "|96      |2013-07-25 00:00:00|8683            |PENDING     |\n",
      "|97      |2013-07-25 00:00:00|10784           |PENDING     |\n",
      "|121     |2013-07-26 00:00:00|2074            |PENDING     |\n",
      "|132     |2013-07-26 00:00:00|289             |PENDING     |\n",
      "|158     |2013-07-26 00:00:00|12345           |PENDING     |\n",
      "|167     |2013-07-26 00:00:00|1347            |PENDING     |\n",
      "|181     |2013-07-26 00:00:00|7473            |PENDING     |\n",
      "|188     |2013-07-26 00:00:00|2889            |PENDING     |\n",
      "|189     |2013-07-26 00:00:00|10177           |PENDING     |\n",
      "|190     |2013-07-26 00:00:00|11115           |PENDING     |\n",
      "|206     |2013-07-26 00:00:00|8994            |PENDING     |\n",
      "+--------+-------------------+----------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from Raj.orders_part\").show(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb320b4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"create table Raj.order_Items_part(order_item_id int,order_item_order_id int,order_item_product_id int,order_item_subtotal decimal(17,4),order_item_product_price decimal(17,4)) partitioned by(order_item_quantity int)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c8934ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"insert into table Raj.order_Items_part select * from order_items \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d319ead7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------------+---------------------+-------------------+------------------------+-------------------+\n",
      "|order_item_id|order_item_order_id|order_item_product_id|order_item_subtotal|order_item_product_price|order_item_quantity|\n",
      "+-------------+-------------------+---------------------+-------------------+------------------------+-------------------+\n",
      "|144765       |57861              |743                  |1.0000             |169.9900                |169                |\n",
      "|145535       |58164              |743                  |1.0000             |169.9900                |169                |\n",
      "|145554       |58170              |743                  |1.0000             |169.9900                |169                |\n",
      "|145698       |58232              |743                  |1.0000             |169.9900                |169                |\n",
      "|146153       |58395              |743                  |1.0000             |169.9900                |169                |\n",
      "|146591       |58574              |743                  |1.0000             |169.9900                |169                |\n",
      "|146625       |58588              |743                  |1.0000             |169.9900                |169                |\n",
      "|147088       |58762              |743                  |1.0000             |169.9900                |169                |\n",
      "|147240       |58828              |743                  |1.0000             |169.9900                |169                |\n",
      "|147358       |58870              |743                  |1.0000             |169.9900                |169                |\n",
      "|148741       |59415              |743                  |1.0000             |169.9900                |169                |\n",
      "|149147       |59589              |743                  |1.0000             |169.9900                |169                |\n",
      "|149229       |59625              |743                  |1.0000             |169.9900                |169                |\n",
      "|149690       |59803              |743                  |1.0000             |169.9900                |169                |\n",
      "|149742       |59826              |743                  |1.0000             |169.9900                |169                |\n",
      "|150176       |59999              |743                  |1.0000             |169.9900                |169                |\n",
      "|150332       |60063              |743                  |1.0000             |169.9900                |169                |\n",
      "|150368       |60081              |743                  |1.0000             |169.9900                |169                |\n",
      "|150498       |60138              |743                  |1.0000             |169.9900                |169                |\n",
      "|150843       |60287              |743                  |1.0000             |169.9900                |169                |\n",
      "+-------------+-------------------+---------------------+-------------------+------------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from Raj.order_Items_part \").show(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc2845b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+----------------------------------+-------+\n",
      "|col_name                    |data_type                         |comment|\n",
      "+----------------------------+----------------------------------+-------+\n",
      "|order_item_id               |int                               |null   |\n",
      "|order_item_order_id         |int                               |null   |\n",
      "|order_item_product_id       |int                               |null   |\n",
      "|order_item_subtotal         |decimal(17,4)                     |null   |\n",
      "|order_item_product_price    |decimal(17,4)                     |null   |\n",
      "|order_item_quantity         |int                               |null   |\n",
      "|# Partition Information     |                                  |       |\n",
      "|# col_name                  |data_type                         |comment|\n",
      "|order_item_quantity         |int                               |null   |\n",
      "|                            |                                  |       |\n",
      "|# Detailed Table Information|                                  |       |\n",
      "|Database                    |raj                               |       |\n",
      "|Table                       |order_items_part                  |       |\n",
      "|Owner                       |itv001389                         |       |\n",
      "|Created Time                |Sat Oct 16 13:26:41 EDT 2021      |       |\n",
      "|Last Access                 |Wed Dec 31 19:00:00 EST 1969      |       |\n",
      "|Created By                  |Spark 2.4.7                       |       |\n",
      "|Type                        |MANAGED                           |       |\n",
      "|Provider                    |hive                              |       |\n",
      "|Table Properties            |[transient_lastDdlTime=1634405201]|       |\n",
      "+----------------------------+----------------------------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"describe formatted Raj.order_Items_part\").show(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ac79368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------+-----------+\n",
      "|database|tableName         |isTemporary|\n",
      "+--------+------------------+-----------+\n",
      "|raj     |order_immu        |false      |\n",
      "|raj     |orderitem_nor     |false      |\n",
      "|raj     |orderitem_orc     |false      |\n",
      "|raj     |orderitem_par     |false      |\n",
      "|raj     |order_items       |false      |\n",
      "|raj     |order_items_part  |false      |\n",
      "|raj     |order_oi          |false      |\n",
      "|raj     |order_oi_cast     |false      |\n",
      "|raj     |order_oi_cast1    |false      |\n",
      "|raj     |order_oi_sum1     |false      |\n",
      "|raj     |order_oi_sum2     |false      |\n",
      "|raj     |order_orc         |false      |\n",
      "|raj     |orders            |false      |\n",
      "|raj     |order_skip_header |false      |\n",
      "|raj     |order_skip_header1|false      |\n",
      "|raj     |order_skip_header2|false      |\n",
      "|raj     |order_skip_header3|false      |\n",
      "|raj     |order_snap        |false      |\n",
      "|raj     |orders_part       |false      |\n",
      "+--------+------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show tables\").show(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "78accf64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+---------------+-------------+-------------------+------------------------+\n",
      "|order_id|         order_date|   order_status|order_item_id|order_item_quantity|order_item_product_price|\n",
      "+--------+-------------------+---------------+-------------+-------------------+------------------------+\n",
      "|       1|2013-07-25 00:00:00|         CLOSED|            1|                  1|                  1.0000|\n",
      "|       2|2013-07-25 00:00:00|PENDING_PAYMENT|            2|                  1|                  1.0000|\n",
      "|       2|2013-07-25 00:00:00|PENDING_PAYMENT|            3|                  5|                  5.0000|\n",
      "|       2|2013-07-25 00:00:00|PENDING_PAYMENT|            4|                  1|                  1.0000|\n",
      "|       4|2013-07-25 00:00:00|         CLOSED|            5|                  2|                  2.0000|\n",
      "|       4|2013-07-25 00:00:00|         CLOSED|            6|                  5|                  5.0000|\n",
      "|       4|2013-07-25 00:00:00|         CLOSED|            7|                  3|                  3.0000|\n",
      "|       4|2013-07-25 00:00:00|         CLOSED|            8|                  4|                  4.0000|\n",
      "|       5|2013-07-25 00:00:00|       COMPLETE|            9|                  1|                  1.0000|\n",
      "|       5|2013-07-25 00:00:00|       COMPLETE|           10|                  5|                  5.0000|\n",
      "+--------+-------------------+---------------+-------------+-------------------+------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from order_oi\").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeeb8ab9",
   "metadata": {},
   "source": [
    "#####   Before creating partitions on multiple tables first need to join the tables into a single table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "824219ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lastException: Throwable = null\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"create table Raj.order_oi_partit(order_id int,order_item_id int,order_item_quantity int,order_item_product_price decimal(17,4),order_date timestamp,order_status string) \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2256f244",
   "metadata": {},
   "source": [
    "#####   while creating partitions order of the columns are important as they should be in an order else data will get shuffeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "eb760fbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lastException: Throwable = null\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"insert into table Raj.order_oi_partit select a.order_id,b.order_item_id,b.order_item_quantity,b.order_item_quantity,a.order_date,a.order_status from orders a join order_items b on (a.order_id=b.order_item_order_id)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "da8bed87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------+-------------------+------------------------+-------------------+---------------+\n",
      "|order_id|order_item_id|order_item_quantity|order_item_product_price|         order_date|   order_status|\n",
      "+--------+-------------+-------------------+------------------------+-------------------+---------------+\n",
      "|       1|            1|                  1|                  1.0000|2013-07-25 00:00:00|         CLOSED|\n",
      "|       2|            2|                  1|                  1.0000|2013-07-25 00:00:00|PENDING_PAYMENT|\n",
      "|       2|            3|                  5|                  5.0000|2013-07-25 00:00:00|PENDING_PAYMENT|\n",
      "|       2|            4|                  1|                  1.0000|2013-07-25 00:00:00|PENDING_PAYMENT|\n",
      "|       4|            5|                  2|                  2.0000|2013-07-25 00:00:00|         CLOSED|\n",
      "+--------+-------------+-------------------+------------------------+-------------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from Raj.order_oi_partit\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "419184c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lastException: Throwable = null\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"create table Raj.order_oi_partition(order_id int,order_item_id int,order_item_quantity int,order_item_product_price decimal(17,4)) partitioned by (order_date timestamp,order_status string)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9868e214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------+-----------+\n",
      "|database|tableName         |isTemporary|\n",
      "+--------+------------------+-----------+\n",
      "|raj     |order_immu        |false      |\n",
      "|raj     |orderitem_nor     |false      |\n",
      "|raj     |orderitem_orc     |false      |\n",
      "|raj     |orderitem_par     |false      |\n",
      "|raj     |order_items       |false      |\n",
      "|raj     |order_items_part  |false      |\n",
      "|raj     |order_oi          |false      |\n",
      "|raj     |order_oi_cast     |false      |\n",
      "|raj     |order_oi_cast1    |false      |\n",
      "|raj     |order_oi_part     |false      |\n",
      "|raj     |order_oi_part1    |false      |\n",
      "|raj     |order_oi_part2    |false      |\n",
      "|raj     |order_oi_partit   |false      |\n",
      "|raj     |order_oi_partition|false      |\n",
      "|raj     |order_oi_sum1     |false      |\n",
      "|raj     |order_oi_sum2     |false      |\n",
      "|raj     |order_orc         |false      |\n",
      "|raj     |orders            |false      |\n",
      "|raj     |order_skip_header |false      |\n",
      "|raj     |order_skip_header1|false      |\n",
      "+--------+------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show tables\").show(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc9753f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[key: string, value: string]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"SET hive.exec.max.dynamic.partitions=100000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5264531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[key: string, value: string]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"SET hive.exec.max.dynamic.partitions.pernode=100000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8101382c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"insert into table Raj.order_oi_partition select * from Raj.order_oi_partit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace57df0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark 2 - Scala",
   "language": "scala",
   "name": "spark_2_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
